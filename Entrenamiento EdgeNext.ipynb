{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28e86d64-5592-4014-8b34-6c14961b4c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\epsilon\\anaconda3\\envs\\explainable_ai\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import timm\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score, precision_score, recall_score, balanced_accuracy_score, confusion_matrix\n",
    "import time\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06ae474e-841e-4d5f-b21d-7a5f87a0207a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "DATA_PATH = \"data/\"\n",
    "ORIGINAL_IMAGE_PATH = os.path.join(DATA_PATH, \"images\")\n",
    "SYNTHETIC_IMAGE_PATH = os.path.join(DATA_PATH, \"synthetic_images\")\n",
    "TRAIN_CSV_PATH = os.path.join(DATA_PATH, \"train_split.csv\")\n",
    "VAL_CSV_PATH = os.path.join(DATA_PATH, \"validation_split.csv\")\n",
    "MODEL_SAVE_PATH = \"models\"\n",
    "BEST_MODEL_SAVE_PATH = os.path.join(MODEL_SAVE_PATH, \"edgenext_best_model.pth\") # Path para guardar mejor modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f768b04e-9b26-4716-8df2-1a68ef255018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/images data/synthetic_images data/train_split.csv data/validation_split.csv\n"
     ]
    }
   ],
   "source": [
    "print(ORIGINAL_IMAGE_PATH, SYNTHETIC_IMAGE_PATH, TRAIN_CSV_PATH, VAL_CSV_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d5a658c-e80e-4dc6-b241-07b24c3c1fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Propiedades data\n",
    "IMAGE_ID_COL = \"isic_id\"\n",
    "TARGET_COL = \"malignant\"\n",
    "IMAGE_EXTENSION = \".jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2655f1a1-206a-4a37-9b28-203d65e86cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parametros modelo\n",
    "MODEL_NAME = 'edgenext_base.in21k_ft_in1k'\n",
    "NUM_CLASSES = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1adbbc88-3c29-4e31-b314-f35c8e88e730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hiperparametros\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 1e-4\n",
    "NUM_EPOCHS = 1\n",
    "WEIGHT_DECAY = 0.01  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0eebaa12-4db0-44b4-9605-768ec002de50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar GPU\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device(\"cuda\")\n",
    "else:\n",
    "    DEVICE = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8279cc3-d732-4621-b149-b0c737834562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hilos Dataloader\n",
    "NUM_WORKERS = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262ddda5-db26-45b9-bd66-0d9528c67970",
   "metadata": {},
   "source": [
    "## 2. DefiniciÃ³n de transformaciones de imagenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d64c676-51c8-4355-925f-f49d8fb8a6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener data de entrenamiento modelo preentrenado HuggingFace\n",
    "model_cfg = timm.get_pretrained_cfg(MODEL_NAME)\n",
    "IMG_SIZE = model_cfg.input_size[1]\n",
    "NORM_MEAN = model_cfg.mean\n",
    "NORM_STD = model_cfg.std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "687878e4-4800-4640-a42b-1a694aa9adbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformaciones para aumentar el conjunto de entrenamiento\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=15),\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.05),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=NORM_MEAN, std=NORM_STD),\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=NORM_MEAN, std=NORM_STD),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866726df-8fe6-4387-9e02-8576233b7b46",
   "metadata": {},
   "source": [
    "## 3. Crear Datasets y Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e51e0b9c-bce5-4f2c-aa7e-e6f177c38d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clase dataloader custom\n",
    "class ISICDataset(Dataset):\n",
    "    def __init__(self, csv_path, original_image_dir, image_id_col, target_col,\n",
    "                 transforms=None, mode='train',\n",
    "                 path_to_synthetic_images_to_use=None,\n",
    "                 synthetic_positive_label=1, # Label para imagenes sinteticas\n",
    "                 image_extension='.jpg'):\n",
    "        \n",
    "        self.mode = mode\n",
    "        self.original_image_dir = original_image_dir\n",
    "        self.image_id_col = image_id_col\n",
    "        self.target_col = target_col\n",
    "        self.transforms = transforms\n",
    "        self.path_to_synthetic_images_to_use = path_to_synthetic_images_to_use\n",
    "        self.synthetic_positive_label = synthetic_positive_label\n",
    "        self.image_extension = image_extension\n",
    "\n",
    "        self.samples = []\n",
    "        self.label_counts = Counter()\n",
    "    \n",
    "        # Leer csv con datos originales y cargar imagenes originales\n",
    "        self.original_df = pd.read_csv(csv_path)\n",
    "        for idx, row in self.original_df.iterrows():\n",
    "            image_id = row[self.image_id_col]\n",
    "            image_path = os.path.join(self.original_image_dir, str(image_id) + self.image_extension)\n",
    "            label = int(row[self.target_col])\n",
    "            self.samples.append({'path': image_path, 'label': label, 'source': 'original'})\n",
    "            self.label_counts[label] += 1 # Para determianr si dataset esta desbalanceado\n",
    "\n",
    "\n",
    "        # En modo entrenamiento cargar imagenes sinteticas\n",
    "        if self.mode == 'train' and self.path_to_synthetic_images_to_use:\n",
    "            synthetic_added_count = 0\n",
    "            for img_filename in os.listdir(self.path_to_synthetic_images_to_use):\n",
    "                if img_filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif')):\n",
    "                    image_path = os.path.join(self.path_to_synthetic_images_to_use, img_filename)\n",
    "                    # Imagenes sinteticas tienen la misma label\n",
    "                    label = self.synthetic_positive_label\n",
    "                    self.samples.append({'path': image_path, 'label': label, 'source': 'synthetic'})\n",
    "                    self.label_counts[label] += 1\n",
    "                    synthetic_added_count += 1\n",
    "        \n",
    "        # Printear distribucion de labels\n",
    "        print(f\"Distribuciones de labels conjunto {self.mode}:\")\n",
    "\n",
    "        for label, count in sorted(self.label_counts.items()):\n",
    "            percentage = (count / len(self.samples)) * 100 if len(self.samples) > 0 else 0\n",
    "            print(f\"  Label {label}: {count} samples ({percentage:.2f}%)\")\n",
    "        print(\"-\" * 30)\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample_info = self.samples[idx]\n",
    "        image_path = sample_info['path']\n",
    "        label = sample_info['label']\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        if self.transforms:\n",
    "            image = self.transforms(image)\n",
    "        return image, torch.tensor(label, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00834333-ef6f-4ed4-b30c-5ab8a7cf0c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Creando dataset entrenamiento ---\n",
      "Distribuciones de labels conjunto train:\n",
      "  Label 0: 272452 samples (95.61%)\n",
      "  Label 1: 12495 samples (4.39%)\n",
      "------------------------------\n",
      "\n",
      "--- Creando dataset de validacion ---\n",
      "Distribuciones de labels conjunto val:\n",
      "  Label 0: 48081 samples (99.90%)\n",
      "  Label 1: 47 samples (0.10%)\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Crear datasets\n",
    "print(\"--- Creando dataset entrenamiento ---\")\n",
    "train_dataset = ISICDataset(\n",
    "    csv_path=TRAIN_CSV_PATH,\n",
    "     original_image_dir=ORIGINAL_IMAGE_PATH,\n",
    "     image_id_col=IMAGE_ID_COL,\n",
    "     target_col=TARGET_COL,\n",
    "     transforms=train_transforms,\n",
    "     mode='train',\n",
    "     path_to_synthetic_images_to_use=SYNTHETIC_IMAGE_PATH,\n",
    "     synthetic_positive_label=1,\n",
    "     image_extension=IMAGE_EXTENSION\n",
    ")\n",
    "\n",
    "print(\"\\n--- Creando dataset de validacion ---\")\n",
    "val_dataset = ISICDataset(\n",
    "    csv_path=VAL_CSV_PATH,\n",
    "    original_image_dir=ORIGINAL_IMAGE_PATH,\n",
    "    image_id_col=IMAGE_ID_COL,\n",
    "    target_col=TARGET_COL,\n",
    "    transforms=val_transforms,\n",
    "    mode='val',\n",
    "    image_extension=IMAGE_EXTENSION\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b958a93-78d5-4de4-97a9-86837dca4d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear Dataloaders a partir de datasets\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True if DEVICE.type == 'cuda' else False)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True if DEVICE.type == 'cuda' else False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f281e54f-896e-41f9-96e3-b182e3461c0e",
   "metadata": {},
   "source": [
    "## 4. Cargar modelo preentrenado y definir loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98073ded-59db-4062-ad4e-d7a66c27765f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar modelo preentrenado\n",
    "model = timm.create_model(\n",
    "    MODEL_NAME,\n",
    "    pretrained=True,\n",
    "    num_classes=NUM_CLASSES\n",
    ")\n",
    "\n",
    "model = model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "387bf78f-afb3-4291-b748-c3f9910a812d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pesos clase 0 , 1: [0.5229306221008301, 11.402441024780273]\n"
     ]
    }
   ],
   "source": [
    "# Balancear funcion de perdida\n",
    "counts = train_dataset.label_counts\n",
    "count_class_0 = counts.get(0, 0)\n",
    "count_class_1 = counts.get(1, 0)\n",
    "\n",
    "\n",
    "# Peso = N / (2 * N de la clase)\n",
    "weight_for_0 = (count_class_0 + count_class_1) / (NUM_CLASSES * count_class_0)\n",
    "weight_for_1 = (count_class_0 + count_class_1) / (NUM_CLASSES * count_class_1)\n",
    "class_weights = torch.tensor([weight_for_0, weight_for_1], dtype=torch.float32).to(DEVICE)\n",
    "\n",
    "print(f\"Pesos clase 0 , 1: {class_weights.cpu().tolist()}\")\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "# Optimizador ADAM\n",
    "optimizer = optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=LEARNING_RATE,\n",
    "    weight_decay=WEIGHT_DECAY\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e130ba11-d123-4e90-b692-09049f0f3acb",
   "metadata": {},
   "source": [
    "## 5. Funciones de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "236280fb-9db5-41ab-af1c-9442d26b7148",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, train_loader, criterion, optimizer, device, epoch_num, num_epochs, num_classes):\n",
    "    model.train()\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    all_labels_list = []\n",
    "    all_preds_proba_list = []\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        \n",
    "        # Guardar metricas y labels de epoca\n",
    "        all_labels_list.extend(labels.detach().cpu().numpy())\n",
    "        probs = torch.softmax(outputs, dim=1)[:, 1].detach().cpu().numpy()\n",
    "        all_preds_proba_list.extend(probs)\n",
    "\n",
    "        if (batch_idx + 1) % 50 == 0:\n",
    "            print(f\"  Epoch [{epoch_num+1}/{num_epochs}] Batch [{batch_idx+1}/{len(train_loader)}] Train Loss: {loss.item():.4f}\")\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    \n",
    "    # Convertir lista a numpy array para sklearn\n",
    "    all_labels_np = np.array(all_labels_list)\n",
    "    all_preds_proba_np = np.array(all_preds_proba_list)\n",
    "    \n",
    "    # Calculo de metricas para la epoca\n",
    "    predicted_classes_np = (all_preds_proba_np >= 0.5).astype(int)\n",
    "    epoch_auc = roc_auc_score(all_labels_np, all_preds_proba_np)\n",
    "    epoch_f1 = f1_score(all_labels_np, predicted_classes_np, pos_label=1, zero_division=0)\n",
    "    epoch_recall = recall_score(all_labels_np, predicted_classes_np, pos_label=1, zero_division=0)\n",
    "    epoch_precision = precision_score(all_labels_np, predicted_classes_np, pos_label=1, zero_division=0)\n",
    "\n",
    "    epoch_balanced_acc = balanced_accuracy_score(all_labels_np, predicted_classes_np)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    epoch_duration = end_time - start_time\n",
    "    \n",
    "    print(f\"Epoch [{epoch_num+1}/{num_epochs}] Train Loss: {epoch_loss:.4f}, AUC: {epoch_auc:.4f}, BalAcc: {epoch_balanced_acc:.4f}, F1: {epoch_f1:.4f}, Recall: {epoch_recall:.4f}, Precision: {epoch_precision:.4f}, Time: {epoch_duration:.2f}s\")\n",
    "    \n",
    "    metrics = {\n",
    "        'loss': epoch_loss,\n",
    "        'auc': epoch_auc,\n",
    "        'balanced_accuracy': epoch_balanced_acc,\n",
    "        'f1_score': epoch_f1,\n",
    "        'recall': epoch_recall,\n",
    "        'precision': epoch_precision\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def validate_one_epoch(model, val_loader, criterion, device, epoch_num, num_epochs, num_classes):\n",
    "    model.eval()\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    all_labels_list = []\n",
    "    all_preds_proba_list = []\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (images, labels) in enumerate(val_loader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            \n",
    "            all_labels_list.extend(labels.detach().cpu().numpy())\n",
    "            probs = torch.softmax(outputs, dim=1)[:, 1].detach().cpu().numpy()\n",
    "            all_preds_proba_list.extend(probs)\n",
    "\n",
    "    epoch_loss = running_loss / len(val_loader.dataset)\n",
    "    \n",
    "    all_labels_np = np.array(all_labels_list)\n",
    "    all_preds_proba_np = np.array(all_preds_proba_list)\n",
    "\n",
    "    if len(np.unique(all_labels_np)) < 2 :\n",
    "        print(f\"Warning: Conjunto de validacion para epoca {epoch_num+1} le falta una clase!.\")\n",
    "        epoch_auc = 0.5\n",
    "    else:\n",
    "        epoch_auc = roc_auc_score(all_labels_np, all_preds_proba_np)\n",
    "    \n",
    "    predicted_classes_np = (all_preds_proba_np >= 0.5).astype(int)\n",
    "    epoch_f1 = f1_score(all_labels_np, predicted_classes_np, pos_label=1, zero_division=0)\n",
    "    epoch_recall = recall_score(all_labels_np, predicted_classes_np, pos_label=1, zero_division=0)\n",
    "    epoch_precision = precision_score(all_labels_np, predicted_classes_np, pos_label=1, zero_division=0)\n",
    "    conf_matrix = confusion_matrix(all_labels_np, predicted_classes_np, labels=[0,1])\n",
    "\n",
    "    epoch_balanced_acc = balanced_accuracy_score(all_labels_np, predicted_classes_np)\n",
    "\n",
    "    end_time = time.time()\n",
    "    epoch_duration = end_time - start_time\n",
    "\n",
    "    print(f\"Epoch [{epoch_num+1}/{num_epochs}] Val Loss: {epoch_loss:.4f}, AUC: {epoch_auc:.4f}, BalAcc: {epoch_balanced_acc:.4f}, F1(pos): {epoch_f1:.4f}, Recall(pos): {epoch_recall:.4f}, Precision(pos): {epoch_precision:.4f}, Time: {epoch_duration:.2f}s\")\n",
    "    if conf_matrix is not None:\n",
    "        print(f\"Matriz de confusion para epoca {epoch_num+1}:\\n{conf_matrix}\")\n",
    "    \n",
    "    metrics = {\n",
    "        'loss': epoch_loss,\n",
    "        'auc': epoch_auc,\n",
    "        'balanced_accuracy': epoch_balanced_acc,\n",
    "        'f1_score_positive': epoch_f1,\n",
    "        'recall_positive': epoch_recall,\n",
    "        'precision_positive': epoch_precision,\n",
    "        'conf_matrix': conf_matrix\n",
    "    }\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b397fe-dd47-4d7a-bc4e-c04788331688",
   "metadata": {},
   "source": [
    "## 6. Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81b3b60-ff31-494c-ac8e-f089089f7881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Entrenamiento ---\n",
      "\n",
      "===== Epoch 1/1 =====\n",
      "Tasa de aprendizaje: 1.000000e-04\n",
      "  Epoch [1/1] Batch [50/8905] Train Loss: 0.0051\n",
      "  Epoch [1/1] Batch [100/8905] Train Loss: 1.5077\n",
      "  Epoch [1/1] Batch [150/8905] Train Loss: 0.0006\n",
      "  Epoch [1/1] Batch [200/8905] Train Loss: 0.0019\n",
      "  Epoch [1/1] Batch [250/8905] Train Loss: 0.0009\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Entrenamiento ---\")\n",
    "\n",
    "# Listas para trackeo\n",
    "train_history = []\n",
    "val_history = []\n",
    "\n",
    "best_val_auc = 0.0\n",
    "\n",
    "start_training_time = time.time()\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(f\"\\n===== Epoch {epoch+1}/{NUM_EPOCHS} =====\")\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    print(f\"Tasa de aprendizaje: {current_lr:.6e}\")\n",
    "\n",
    "\n",
    "    # --- Entrenamiento ---\n",
    "    if train_loader:\n",
    "        train_metrics = train_one_epoch(model, train_loader, criterion, optimizer, DEVICE, epoch, NUM_EPOCHS, NUM_CLASSES)\n",
    "        train_history.append(train_metrics)\n",
    "    else:\n",
    "        train_history.append({'loss': float('nan'), 'auc': float('nan'), 'balanced_accuracy': float('nan'), 'f1_score': float('nan'), 'recall': float('nan'), 'precision': float('nan')})\n",
    "\n",
    "    # --- Validacion ---\n",
    "    if val_loader:\n",
    "        val_metrics = validate_one_epoch(model, val_loader, criterion, DEVICE, epoch, NUM_EPOCHS, NUM_CLASSES)\n",
    "        val_history.append(val_metrics)\n",
    "\n",
    "        # --- Checkpoint ---\n",
    "        current_val_auc = val_metrics['auc']\n",
    "        if current_val_auc > best_val_auc:\n",
    "            best_val_auc = current_val_auc\n",
    "            torch.save(model.state_dict(), BEST_MODEL_SAVE_PATH)\n",
    "            print(f\"Epoch {epoch+1}: Mejor modelo con AUC: {best_val_auc:.4f} guardado en {BEST_MODEL_SAVE_PATH}\")\n",
    "        \n",
    "    else:\n",
    "        val_history.append({'loss': float('nan'), 'auc': float('nan'), 'balanced_accuracy': float('nan'), 'f1_score_positive': float('nan'), 'recall_positive': float('nan'), 'precision_positive': float('nan'), 'conf_matrix': None })\n",
    "\n",
    "\n",
    "end_training_time = time.time()\n",
    "total_training_duration = end_training_time - start_training_time\n",
    "print(f\"\\n--- Entrenamiento terminado ---\")\n",
    "print(f\"Tiempo: {total_training_duration / 60:.2f} minutos ({total_training_duration:.2f} segundos)\")\n",
    "if val_loader:\n",
    "    print(f\"Mejor AUC validacion: {best_val_auc:.4f}\")\n",
    "    print(f\"Nombre mejor modelo: {BEST_MODEL_SAVE_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10eb3fd9-03cb-408f-be63-4aaf19c78fe6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
