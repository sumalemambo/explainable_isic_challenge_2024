{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "28e86d64-5592-4014-8b34-6c14961b4c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import timm\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score, precision_score, recall_score\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "06ae474e-841e-4d5f-b21d-7a5f87a0207a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "DATA_PATH = \"data/\"\n",
    "ORIGINAL_IMAGE_PATH = os.path.join(DATA_PATH, \"images\")\n",
    "SYNTHETIC_IMAGE_PATH = os.path.join(DATA_PATH, \"synthetic_images\")\n",
    "TRAIN_CSV_PATH = os.path.join(DATA_PATH, \"train_split.csv\")\n",
    "VAL_CSV_PATH = os.path.join(DATA_PATH, \"val_split.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f768b04e-9b26-4716-8df2-1a68ef255018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/images data/synthetic_images data/train_split.csv data/val_split.csv\n"
     ]
    }
   ],
   "source": [
    "print(ORIGINAL_IMAGE_PATH, SYNTHETIC_IMAGE_PATH, TRAIN_CSV_PATH, VAL_CSV_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1adbbc88-3c29-4e31-b314-f35c8e88e730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parametros\n",
    "NUM_CLASSES = 2\n",
    "MODEL_NAME = 'edgenext_base.in21k_ft_in1k'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262ddda5-db26-45b9-bd66-0d9528c67970",
   "metadata": {},
   "source": [
    "## 2. DefiniciÃ³n de transformaciones de imagenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d64c676-51c8-4355-925f-f49d8fb8a6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener data de entrenamiento modelo preentrenado HuggingFace\n",
    "MODEL_NAME = 'edgenext_base.in21k_ft_in1k'\n",
    "model_cfg = timm.get_pretrained_cfg(MODEL_NAME)\n",
    "IMG_SIZE = model_cfg.input_size[1]\n",
    "NORM_MEAN = model_cfg.mean\n",
    "NORM_STD = model_cfg.std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "687878e4-4800-4640-a42b-1a694aa9adbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformaciones para aumentar el conjunto de entrenamiento\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=15),\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.05),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=NORM_MEAN, std=NORM_STD),\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=NORM_MEAN, std=NORM_STD),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866726df-8fe6-4387-9e02-8576233b7b46",
   "metadata": {},
   "source": [
    "## 3. Crear DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e51e0b9c-bce5-4f2c-aa7e-e6f177c38d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clase dataloader custom\n",
    "class ISICDataset(Dataset):\n",
    "    def __init__(self, csv_path, original_image_dir, image_id_col, target_col,\n",
    "                 transforms=None, mode='train',\n",
    "                 path_to_synthetic_images_to_use=None,\n",
    "                 synthetic_positive_label=1, # Label para imagenes sinteticas\n",
    "                 image_extension='.png'):\n",
    "        \n",
    "        self.mode = mode\n",
    "        self.original_image_dir = original_image_dir\n",
    "        self.image_id_col = image_id_col\n",
    "        self.target_col = target_col\n",
    "        self.transforms = transforms\n",
    "        self.path_to_synthetic_images_to_use = path_to_synthetic_images_to_use\n",
    "        self.synthetic_positive_label = synthetic_positive_label\n",
    "        self.image_extension = image_extension\n",
    "\n",
    "        self.samples = []\n",
    "        self.label_counts = Counter()\n",
    "    \n",
    "        # Leer csv con datos originales y cargar imagenes originales\n",
    "        self.original_df = pd.read_csv(csv_path)\n",
    "        for idx, row in self.original_df.iterrows():\n",
    "            image_id = row[self.image_id_col]\n",
    "            image_path = os.path.join(self.original_image_dir, str(image_id) + self.image_extension)\n",
    "            label = int(row[self.target_col])\n",
    "            self.samples.append({'path': image_path, 'label': label, 'source': 'original'})\n",
    "            self.label_counts[label] += 1 # Para determianr si dataset esta desbalanceado\n",
    "\n",
    "\n",
    "        # En modo entrenamiento cargar imagenes sinteticas\n",
    "        if self.mode == 'train' and self.path_to_synthetic_images_to_use:\n",
    "            synthetic_added_count = 0\n",
    "            for img_filename in os.listdir(self.path_to_synthetic_images_to_use):\n",
    "                if img_filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif')):\n",
    "                    image_path = os.path.join(self.path_to_synthetic_images_to_use, img_filename)\n",
    "                    # Imagenes sinteticas tienen la misma label\n",
    "                    label = self.synthetic_positive_label\n",
    "                    self.samples.append({'path': image_path, 'label': label, 'source': 'synthetic'})\n",
    "                    self.label_counts[label] += 1\n",
    "                    synthetic_added_count += 1\n",
    "        \n",
    "        # Printear distribucion de labels\n",
    "        print(f\"Distribuciones de labels conjunto {self.mode}:\")\n",
    "\n",
    "        for label, count in sorted(self.label_counts.items()):\n",
    "            percentage = (count / len(self.samples)) * 100 if len(self.samples) > 0 else 0\n",
    "            print(f\"  Label {label}: {count} samples ({percentage:.2f}%)\")\n",
    "        print(\"-\" * 30)\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample_info = self.samples[idx]\n",
    "        image_path = sample_info['path']\n",
    "        label = sample_info['label']\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        if self.transforms:\n",
    "            image = self.transforms(image)\n",
    "        return image, torch.tensor(label, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "00834333-ef6f-4ed4-b30c-5ab8a7cf0c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Creating Training Dataset ---\n",
      "Label distribution for train set:\n",
      "  Label 0: 272452 samples (95.61%)\n",
      "  Label 1: 12495 samples (4.39%)\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 32 # Ensure this is defined\n",
    "NUM_WORKERS = 0 # Start with 0 for debugging, then increase to 2 or 4\n",
    "\n",
    "IMAGE_ID_COL = \"isic_id\"\n",
    "TARGET_COL = \"malignant\"\n",
    "SYNTHETIC_HR_DIR_FOR_TRAINING = \"data/synthetic_images/\"\n",
    "IMAGE_EXTENSION = \".png\"\n",
    "\n",
    "print(\"--- Creating Training Dataset ---\")\n",
    "train_dataset = ISICDataset(\n",
    "    csv_path=TRAIN_CSV_PATH,\n",
    "     original_image_dir=ORIGINAL_IMAGE_PATH,\n",
    "     image_id_col=IMAGE_ID_COL,\n",
    "     target_col=TARGET_COL,\n",
    "     transforms=train_transforms,\n",
    "     mode='train',\n",
    "     path_to_synthetic_images_to_use=SYNTHETIC_HR_DIR_FOR_TRAINING, # e.g., 'data/synthetic_images/hr'\n",
    "     synthetic_positive_label=1, # Crucial: ensure this aligns with your positive class label\n",
    "     image_extension=IMAGE_EXTENSION\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f43a2c5-11be-43b7-aa89-75f3afa275bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
